# ğŸš€ Data Engineering Journey

A week-by-week, hands-on path to becoming a **production-ready Data Engineer**.  
This repo is organized by week; each folder contains a focused `README.md`, plus **Glossary**, **Notes**, **Summary**, and any **labs/assignments/code** for that week.

---

## ğŸ“‚ How to Navigate

Each week folder follows the same pattern:
- `README.md` â€” the week's overview & what was built
- `Glossary.md` â€” quick revision bullets
- `Notes.md` â€” cleaned, mentor-style notes
- `Summary.md` â€” 2â€“3 minute recap
- (optional) lab notebooks / assignments / diagrams

---

## ğŸ“† Weeks Completed

### 1) Week 1 â€” Big Data: The Big Picture
- 5Vs of Big Data, **monolithic vs distributed**
- Hadoop overview: **HDFS / MapReduce / YARN**
- Databases vs **Data Warehouse** vs **Data Lake**
- Role of a Data Engineer, cloud mapping (AWS/Azure/GCP)

ğŸ“ Folder: [`Week1 Big Data - The Big Picture`](./Week1%20Big%20Data%20-%20The%20Big%20Picture/)  
- [README](./Week1%20Big%20Data%20-%20The%20Big%20Picture/README.md) 
- [Glossary](./Week1%20Big%20Data%20-%20The%20Big%20Picture/Glossary.md)

---

### 2) Week 2 â€” Distributed Storage & Data Lake
- HDFS internals: **NameNode/DataNode**, blocks, replication, **rack awareness**, federation
- Linux & HDFS CLI (put/get/ls/cp/mv/fsck)
- **HDFS vs Cloud Data Lakes** (S3/ADLS/GCS): block vs object, decoupled compute

ğŸ“ Folder: [`Week2 Distributed Storage & Data Lake`](./Week2%20Distributed%20Storage%20&%20Data%20Lake/)  
- [README](./Week2%20Distributed%20Storage%20&%20Data%20Lake/README.md) 
- [Glossary](./Week2%20Distributed%20Storage%20&%20Data%20Lake/Week2_Glossary.md)  
- Mini Assignment: [Week2 Mini Assignment â€“ HDFS & Linux Practice](./Week2%20Distributed%20Storage%20&%20Data%20Lake/Week2%20Mini%20Assignment%20â€“%20HDFS%20&%20Linux%20Practice)

---

### 3) Week 3 â€” Distributed Processing Fundamentals
- MapReduce pipeline: **RecordReader â†’ Map â†’ (Combiner) â†’ Partition â†’ Shuffle â†’ Sort â†’ Reduce**
- **Reducers**: when to increase, when to set to 0, custom partitioner
- Real-world pattern: **Inverted Index** (search), **Sensor max per day**
- **Apache Spark** intro: RDDs, lazy eval, DAG, memory vs disk I/O
- Coding: **Word Count with RDD API** (load â†’ flatMap â†’ map â†’ reduceByKey â†’ save)

ğŸ“ Folder: [`Week 3 Distributed Processing Fundamentals`](./Week%203%20Distributed%20Processing%20Fundamentals/)  
- [README](./Week%203%20Distributed%20Processing%20Fundamentals/README.md) 
- [Glossary](./Week%203%20Distributed%20Processing%20Fundamentals/Week3_Glossary.md)  
- [Distributed Processing Notes](./Week%203%20Distributed%20Processing%20Fundamentals/Week3_Distributed_Processing.md)  
- [Summary](./Week%203%20Distributed%20Processing%20Fundamentals/Week3_Summary.md)

---

## ğŸ“Š Data Engineering Journey Map

```
Raw Data Sources
      â†“
Ingestion & Landing Zone
      â†“
Distributed Storage (HDFS / S3 / ADLS)
      â†“
Distributed Processing (MapReduce / Spark)
      â†“
Serving Layer (DB / DWH / NoSQL)
      â†“
BI / ML / Applications
```

---

## ğŸ§° Tech Stack & Skills

**Big Data:** HDFS, MapReduce, YARN  
**Processing:** Apache Spark (RDDs, DataFrames/Spark SQL intro), Databricks (indepth) 
**Cloud Data Lakes:** Azure ADLS Gen2
**Orchestration (coming):** ADF, Airflow  
**Serving (context):** RDBMS, Data Warehouse, NoSQL

---

## ğŸ¤ Connect With Me

[![LinkedIn](https://img.shields.io/badge/LinkedIn-blue?style=flat-square&logo=linkedin&logoColor=white&link=https://www.linkedin.com/in/manyue-javvadi-datascientist/)](https://www.linkedin.com/in/manyue-javvadi-datascientist/) 
[![GitHub](https://img.shields.io/badge/GitHub-black?style=flat-square&logo=github&logoColor=white&link=https://github.com/Manyue-datascientist/data-engineering-journey)](https://github.com/Manyue-datascientist/data-engineering-journey)
<!-- alt: GitHub badge with black background, white GitHub logo, and the word GitHub in white text. The badge has a flat square style and links to the Manyue Javvadi GitHub data engineering journey repo. The tone is professional and inviting, set in a clean digital environment. -->

